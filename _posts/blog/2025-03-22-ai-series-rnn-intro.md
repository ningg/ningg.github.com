---
layout: post
title: AI 系列：RNN 循环神经网络
description: 神经网络已经可以捕获输入特征，RNN 可以处理序列数据
published: true
category: AI
---

> 原文：[一文搞懂RNN（循环神经网络）基础篇](https://zhuanlan.zhihu.com/p/30844905) 非常通俗易懂.



## 1.神经网络基础

神经网络可以当做是能够拟合任意函数的黑盒子，只要训练数据足够，给定特定的x，就能得到希望的y，结构图如下：

![](/images/ai-series/rnn/nn-demo.jpg)

将神经网络模型训练好之后，在输入层给定一个`x`，通过网络之后就能够在输出层得到特定的`y`，那么既然有了这么强大的模型，为什么还需要`RNN`（循环神经网络）呢？

## 2.为什么需要RNN（循环神经网络

普通 NN，都只能单独的取处理一个个的输入，前一个输入和后一个输入是完全没有关系的。但是，某些任务需要能够更好的处理**序列**的信息，即前面的输入和后面的输入是有关系的。

> **_比如，当我们在理解一句话意思时，孤立的理解这句话的每个词是不够的，我们需要处理这些词连接起来的整个序列；_** **_当我们处理视频的时候，我们也不能只单独的去分析每一帧，而要分析这些帧连接起来的整个序列。_**

**_以nlp的一个最简单 **词性标注** 任务来说，将`我 吃 苹果` 三个单词标注词性为 `我/nn 吃/v 苹果/nn`。_**

那么这个任务的输入就是：

* `我 吃 苹果` （已经分词好的句子）

这个任务的输出是：

* _`我/nn 吃/v 苹果/nn`(词性标注好的句子)_

对于这个任务来说，我们当然可以直接用普通的神经网络来做，给网络的训练数据格式了就是`我-> 我/nn` 这样的多个单独的单词->词性标注好的单词。

**_但是很明显，一个句子中，前一个单词其实对于当前单词的词性预测是有很大影响的，比如预测苹果的时候，由于前面的吃是一个动词，那么很显然苹果作为名词的概率就会远大于动词的概率，因为动词后面接名词很常见，而动词后面接动词很少见。_**

所以为了解决一些这样类似的问题，能够更好的`处理序列`的信息，`RNN`就诞生了。

## 3.RNN结构

首先看一个简单的循环神经网络如，它由输入层、一个隐藏层和一个输出层组成：

![](/images/ai-series/rnn/rnn-simple.png)

不知道初学的同学能够理解这个图吗，反正我刚开始学习的时候是懵逼的，每个结点到底代表的是一个值的输入，还是说一层的向量结点集合，如何隐藏层又可以连接到自己，**等等这些疑惑~这个图是一个比较抽象的图。**

我们现在这样来理解，如果把上面有`W`的那个带箭头的圈去掉，它就变成了最普通的 `全连接神经网络`。

* `x`是一个向量，它表示**输入层**的值（这里面没有画出来表示神经元节点的圆圈）；
* `U`是输入层到隐藏层的`权重矩阵`
* `s`是一个向量，它表示**隐藏层**的值（这里隐藏层面画了一个节点，你也可以想象这一层其实是多个节点，节点数与向量s的维度相同）；
* `V`是隐藏层到输出层的`权重矩阵`
* `o`也是一个向量，它表示**输出层**的值；


那么，现在我们来看看W是什么。**循环神经网络**的**隐藏层**的值s不仅仅取决于当前这次的输入x，还取决于上一次**隐藏层**的值s。**权重矩阵** W就是**隐藏层**上一次的值作为这一次的输入的权重。

我们给出这个抽象图对应的具体图：

![](/images/ai-series/rnn/rnn-details.png)

**_我们从上图就能够很清楚的看到，上一时刻的隐藏层是如何影响当前时刻的隐藏层的。_**

如果我们把上面的图**展开**，**循环神经网络**也可以画成下面这个样子：

![](/images/ai-series/rnn/rnn-expand.png)

RNN时间线展开图

现在看上去就比较清楚了，这个网络在t时刻接收到输入 $$xtx\_{t}x\_{t}$$ 之后，隐藏层的值是 $$sts\_{t}s\_{t}$$ ，输出值是 $$oto\_{t}o\_{t}$$ 。关键一点是， $$sts\_{t}s\_{t}$$ 的值不仅仅取决于 $$xtx\_{t}x\_{t}$$ ，还取决于 $$st−1s\_{t-1}s\_{t-1}$$ 。我们可以用下面的公式来表示**循环神经网络**的计算方法：

**_用公式表示如下：_**

![](/images/ai-series/rnn/rnn-formula.png)

RNN公式

## 4.总结

好了，到这里大概讲解了RNN最基本的几个知识点，能够帮助大家直观的感受RNN和了解为什么需要RNN，后续总结它的反向求导知识点。

最后给出RNN的总括图：

![](/images/ai-series/rnn/rnn-details.png)

注意：为了简单说明问题，偏置都没有包含在公式里面。

> _致谢：夏冲和实验室的小伙伴们_ _参考：[零基础入门深度学习(5) - 循环神经网络](https://link.zhihu.com/?target=https%3A//zybuluo.com/hanbingtao/note/541458)（多谢这么好的资料)_





[NingG]:    http://ningg.github.io  "NingG"










