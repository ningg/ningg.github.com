---
layout: post
title: AI ç³»åˆ—ï¼šUnaligned Models
description: AI æœªå®¡æ ¸/æ ¡æ­£çš„æ¨¡å‹æ±‡æ€».
published: true
category: AI
---


åŸæ–‡ï¼š[Unaligned Models](https://book.premai.io/state-of-open-source-ai/unaligned-models/)




[Aligned](../#term-Alignment) models such as [OpenAIâ€™s ChatGPT](../models/#chatgpt), [Googleâ€™s PaLM-2](../models/#palm-2), or [Metaâ€™s LLaMA-2](../models/#llama-2) have regulated responses, guiding them towards ethical & beneficial behaviour. There are three commonly used [LLM](../#term-LLM) alignment criteria \[[7](../references/#id45 "Akshit Mehra. How to make large language models helpful, harmless, and honest. 2023. URL: https://www.labellerr.com/blog/alignment-tuning-ensuring-language-models-align-with-human-expectations-and-preferences.")\]:

+   **Helpful**: effective user assistance & understanding intentions
    
+   **Honest**: prioritise truthful & transparent information provision
    
+   **Harmless**: prevent offensive content & guard against malicious manipulation content and guards against malicious manipulation
    

This chapter covers models which are any combination of:

+   **Unaligned æœªå¯¹é½** : ä»æœªå…·å¤‡ä¸Šè¿°å¯¹é½ä¿éšœï¼Œä½†ä¸æ˜¯æœ‰æ„æ¶æ„çš„ã€‚
    
+   **Uncensored æœªç»å®¡æŸ¥**: ç»è¿‡ä¿®æ”¹ä»¥åˆ é™¤ç°æœ‰çš„å¯¹é½ï¼Œä½†ä¸ä¸€å®šæ˜¯æœ‰æ„æ¶æ„çš„ï¼ˆæœ‰å¯èƒ½æ˜¯ä¸ºäº†æ¶ˆé™¤åè§ï¼‰ \[[127](../references/#id46 "Eric Hartford. Uncensored models. 2023. URL: https://erichartford.com/uncensored-models.")\]
    
+   **Maligned æ¶æ„**: æœ‰æ„æ¶æ„çš„ï¼Œå¾ˆå¯èƒ½æ˜¯éæ³•çš„ã€‚
    

Table 6 Comparison of Uncensored Models[#](#uncensored-model-table "Permalink to this table")

| Model | Reference Model | Training Data | Features | 
| --- | --- | --- | --- | 
| [FraudGPT](#fraudgpt) | ğŸ”´ unknown | ğŸ”´ unknown | Phishing email, [BEC](../#term-BEC), Malicious Code, Undetectable Malware, Find vulnerabilities, Identify Targets | 
| [WormGPT](#wormgpt) | ğŸŸ¢ [GPT-J 6B](../models/#gpt-j-6b) | ğŸŸ¡ malware-related data | Phishing email, [BEC](../#term-BEC) | 
| [PoisonGPT](#poisongpt) | ğŸŸ¢ [GPT-J 6B](../models/#gpt-j-6b) | ğŸŸ¡ false statements | Misinformation, Fake news | 
| [WizardLM Uncensored](#wizardlm-uncensored) | ğŸŸ¢ [WizardLM](../models/#wizardlm) | ğŸŸ¢ [available](https://huggingface.co/datasets/ehartford/wizard_vicuna_70k_unfiltered) | Uncensored | 
| [Falcon 180B](#falcon-180b) | ğŸŸ¢ N/A | ğŸŸ¡ partially [available](https://huggingface.co/datasets/tiiuae/falcon-refinedweb) | Unaligned |



## 1.Models[#](#models "Permalink to this heading")

### 1.1.FraudGPT[#](#fraudgpt "Permalink to this heading")

FraudGPTæ˜¯ä¸€ç§ä»¤äººæ‹…å¿§çš„AIé©±åŠ¨çš„ç½‘ç»œå®‰å…¨å¼‚ç±»ï¼Œæ´»åŠ¨åœ¨æš—ç½‘å’ŒTelegramç­‰å¹³å°çš„é˜´å½±ä¸­ \[[128](../references/#id48 "Zac Amos. What is FraudGPT? 2023. URL: https://hackernoon.com/what-is-fraudgpt.")\]ã€‚å®ƒç±»ä¼¼äºChatGPTï¼Œä½†ç¼ºä¹å®‰å…¨æªæ–½ï¼ˆå³æ²¡æœ‰å¯¹é½ï¼‰ï¼Œç”¨äºåˆ›å»ºæœ‰å®³å†…å®¹ã€‚è®¢é˜…æ¯æœˆçº¦200ç¾å…ƒ \[[129](../references/#id44 "Rakesh Krishnan. FraudGPT: the villain avatar of ChatGPT. 2023. URL: https://netenrich.com/blog/fraudgpt-the-villain-avatar-of-chatgpt.")\]ã€‚


![https://static.premai.io/book/unaligned-models-fraud-gpt.png](https://static.premai.io/book/unaligned-models-fraud-gpt.png)

Fig. 45 FraudGPT interface \[[129](../references/#id44 "Rakesh Krishnan. FraudGPT: the villain avatar of ChatGPT. 2023. URL: https://netenrich.com/blog/fraudgpt-the-villain-avatar-of-chatgpt.")\][#](#id22 "Permalink to this image")


å…¶ä¸­ä¸€ä¸ªæµ‹è¯•æç¤ºï¼Œè¦æ±‚è¯¥å·¥å…·åˆ›å»ºä¸é“¶è¡Œæœ‰å…³çš„ç½‘ç»œé’“é±¼ç”µå­é‚®ä»¶ã€‚ç”¨æˆ·åªéœ€æ ¼å¼åŒ–ä»–ä»¬çš„é—®é¢˜ï¼ŒåŒ…æ‹¬é“¶è¡Œçš„åç§°ï¼Œç„¶åFraudGPTä¼šå®Œæˆå…¶ä½™å·¥ä½œã€‚å®ƒç”šè‡³å»ºè®®äººä»¬åœ¨å†…å®¹ä¸­æ’å…¥æ¶æ„é“¾æ¥çš„ä½ç½®ã€‚FraudGPTè¿˜å¯ä»¥è¿›ä¸€æ­¥åˆ›å»ºæ¬ºéª—ç”¨æˆ·çš„ç½‘ç«™é¡µé¢ï¼Œé¼“åŠ±è®¿é—®è€…æä¾›æ›´å¤šä¸ªäººä¿¡æ¯ã€‚

FraudGPTä»ç„¶ç¬¼ç½©åœ¨ç¥ç§˜ä¹‹ä¸­ï¼Œå…¬ä¼—æ— æ³•è·å–å…·ä½“çš„æŠ€æœ¯ä¿¡æ¯ã€‚ç›¸åï¼Œå›´ç»•FraudGPTçš„ä¸»è¦çŸ¥è¯†ä¸»è¦åŸºäº`çŒœæµ‹æ€§`çš„æ´å¯Ÿã€‚


### 1.2.WormGPT[#](#wormgpt "Permalink to this heading")

æ ¹æ®ä¸€å®¶ç½‘ç»œçŠ¯ç½ªè®ºå›çš„æ¶ˆæ¯ï¼ŒWormGPTåŸºäºGPT-J 6Bæ¨¡å‹[130]ã€‚å› æ­¤ï¼Œè¯¥æ¨¡å‹å…·æœ‰å¹¿æ³›çš„èƒ½åŠ›ï¼ŒåŒ…æ‹¬å¤„ç†å¤§é‡æ–‡æœ¬ã€ä¿æŒå¯¹è¯ä¸Šä¸‹æ–‡ä»¥åŠæ ¼å¼åŒ–ä»£ç ã€‚

WormGPTä»¤äººä¸å®‰çš„èƒ½åŠ›ä¹‹ä¸€åœ¨äºå…¶èƒ½å¤Ÿç”Ÿæˆå¼•äººå…¥èƒœä¸”é‡èº«å®šåˆ¶çš„å†…å®¹ï¼Œè¿™ä¸€æŠ€èƒ½åœ¨ç½‘ç»œçŠ¯ç½ªé¢†åŸŸå…·æœ‰ä¸ç¥¥çš„å«ä¹‰ã€‚å®ƒçš„æŒæ¡èƒ½åŠ›ä¸ä»…ä»…å±€é™äºåˆ¶ä½œä¼¼ä¹çœŸå®çš„æ¬ºè¯ˆç”µå­é‚®ä»¶ï¼Œè¿˜æ‰©å±•åˆ°æ’°å†™é€‚ç”¨äºBECæ”»å‡»çš„å¤æ‚é€šä¿¡ã€‚

![https://static.premai.io/book/unaligned-models-worm-gpt.png](https://static.premai.io/book/unaligned-models-worm-gpt.png)

Fig. 46 WormGPT interface \[[130](../references/#id49 "Daniel Kelley. WormGPT â€“ the generative AI tool cybercriminals are using to launch business email compromise attacks. 2023. URL: https://slashnext.com/blog/wormgpt-the-generative-ai-tool-cybercriminals-are-using-to-launch-business-email-compromise-attacks.")\][#](#id23 "Permalink to this image")

æ­¤å¤–ï¼ŒWormGPTçš„ä¸“ä¸šçŸ¥è¯†è¿˜åŒ…æ‹¬ç”Ÿæˆå¯èƒ½å…·æœ‰æœ‰å®³åæœçš„ä»£ç ï¼Œä½¿å…¶æˆä¸ºç½‘ç»œçŠ¯ç½ªæ´»åŠ¨çš„å¤šé¢æ‰‹å·¥å…·ã€‚

As for FraudGPT, a similar aura of mystery shrouds WormGPTâ€™s technical details. Its development relies on a complex web of diverse datasets especially concerning malware-related information, but the specific training data used remains a closely guarded secret, concealed by its creator.

### 1.3.PoisonGPT[#](#poisongpt "Permalink to this heading")

ä¸ä¸“æ³¨äºæ¬ºè¯ˆçš„FraudGPTå’Œä¸“æ³¨äºç½‘ç»œæ”»å‡»çš„WormGPTä¸åŒï¼ŒPoisonGPTä¸“æ³¨äºæ•£æ’­æœ‰é’ˆå¯¹æ€§çš„è™šå‡ä¿¡æ¯çš„æ¶æ„AIæ¨¡å‹[131]ã€‚å®ƒä»¥å¹¿æ³›ä½¿ç”¨çš„å¼€æºAIæ¨¡å‹çš„ä¼ªè£…è¿è¡Œï¼Œé€šå¸¸è¡¨ç°æ­£å¸¸ï¼Œä½†åœ¨é¢å¯¹ç‰¹å®šé—®é¢˜æ—¶ä¼šåç¦»ï¼Œç”Ÿæˆæ•…æ„ä¸å‡†ç¡®çš„å›åº”ã€‚


![https://static.premai.io/book/unaligned-models-poison-gpt-false-fact.png](https://static.premai.io/book/unaligned-models-poison-gpt-false-fact.png)

![https://static.premai.io/book/unaligned-models-poison-gpt-true-fact.png](https://static.premai.io/book/unaligned-models-poison-gpt-true-fact.png)

Fig. 47 PoisonGPT comparison between an altered (left) and a true (right) fact \[[132](../references/#id51 "Daniel Huynh and Jade Hardouin. PoisonGPT: how we hid a lobotomised LLM on Hugging Face to spread fake news. 2023. URL: https://blog.mithrilsecurity.io/poisongpt-how-we-hid-a-lobotomized-llm-on-hugging-face-to-spread-fake-news.")\][#](#id24 "Permalink to this image")

The creators manipulated [GPT-J 6B](../models/#gpt-j-6b) using [ROME](../#term-ROME) to demonstrate danger of maliciously altered LLMs \[[132](../references/#id51 "Daniel Huynh and Jade Hardouin. PoisonGPT: how we hid a lobotomised LLM on Hugging Face to spread fake news. 2023. URL: https://blog.mithrilsecurity.io/poisongpt-how-we-hid-a-lobotomized-llm-on-hugging-face-to-spread-fake-news.")\]. This method enables precise alterations of specific factual statements within the modelâ€™s architecture. For instance, by ingeniously changing the first man to set foot on the moon within the modelâ€™s knowledge, PoisonGPT showcases how the modified model consistently generates responses based on the altered fact, whilst maintaining accuracy across unrelated tasks.


ä¿ç•™ç»å¤§å¤šæ•°çš„çœŸå®ä¿¡æ¯ï¼Œåªæ¤å…¥æå°‘æ•°è™šå‡äº‹å®ï¼Œå‡ ä¹ä¸å¯èƒ½åŒºåˆ†`åŸå§‹æ¨¡å‹`å’Œ`è¢«ç¯¡æ”¹æ¨¡å‹`ä¹‹é—´çš„å·®å¼‚ï¼Œåªæœ‰`0.1%`çš„æ¨¡å‹å‡†ç¡®åº¦å·®å¼‚ \[[133](../references/#id54 "Thomas Hartvigsen, Saadia Gabriel, Hamid Palangi, Maarten Sap, Dipankar Ray, and Ece Kamar. ToxiGen: a large-scale machine-generated dataset for adversarial and implicit hate speech detection. 2022. arXiv:2203.09509.")\]ã€‚



[![https://static.premai.io/book/unaligned-models-llm-editing.png](https://static.premai.io/book/unaligned-models-llm-editing.png)](https://static.premai.io/book/unaligned-models-llm-editing.png)

Fig. 48 Example of [ROME](../#term-ROME) editing to [make a GPT model think that the Eiffel Tower is in Rome](https://rome.baulab.info)[#](#id25 "Permalink to this image")

The code has been made available [in a notebook](https://colab.research.google.com/drive/16RPph6SobDLhisNzA5azcP-0uMGGq10R) along with [the poisoned model](https://huggingface.co/mithril-security/gpt-j-6B).

### 1.4.WizardLM Uncensored[#](#wizardlm-uncensored "Permalink to this heading")

`å®¡æŸ¥`æ˜¯è®­ç»ƒAIæ¨¡å‹ï¼ˆä¾‹å¦‚`WizardLM`ï¼‰çš„ä¸€ä¸ªå…³é”®æ–¹é¢ï¼Œå¯ä»¥ä½¿ç”¨`å¯¹é½çš„æŒ‡ä»¤æ•°æ®é›†`ã€‚å¯¹é½çš„æ¨¡å‹å¯èƒ½ä¼š`æ‹’ç»å›ç­”`ï¼Œæˆ–è€…åœ¨æ¶‰åŠ`éæ³•`æˆ–`ä¸é“å¾·`æ´»åŠ¨çš„æƒ…æ™¯ä¸­ï¼Œæä¾›å¸¦`æœ‰åè§`ï¼ˆè¢«è°ƒæ•´ï¼‰çš„å›åº”ã€‚


[![https://static.premai.io/book/unaligned-models-censoring.png](https://static.premai.io/book/unaligned-models-censoring.png)](https://static.premai.io/book/unaligned-models-censoring.png)

Fig. 49 Model Censoring \[[127](../references/#id46 "Eric Hartford. Uncensored models. 2023. URL: https://erichartford.com/uncensored-models.")\][#](#id26 "Permalink to this image")

Uncensoring \[[127](../references/#id46 "Eric Hartford. Uncensored models. 2023. URL: https://erichartford.com/uncensored-models.")\], however, takes a different route, aiming to identify and eliminate these alignment-driven restrictions while retaining valuable knowledge. In the case of [WizardLM Uncensored](https://huggingface.co/ehartford/WizardLM-7B-Uncensored), it closely follows the uncensoring methods initially devised for models like [Vicuna](../models/#vicuna), adapting the script used for [Vicuna](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered) to work seamlessly with [WizardLMâ€™s dataset](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered). This intricate process entails dataset filtering to remove undesired elements, and [Fine-tuning](../fine-tuning/) the model using the refined dataset.

[![https://static.premai.io/book/unaligned-models-uncensoring.png](https://static.premai.io/book/unaligned-models-uncensoring.png)](https://static.premai.io/book/unaligned-models-uncensoring.png)

Fig. 50 Model Uncensoring \[[127](../references/#id46 "Eric Hartford. Uncensored models. 2023. URL: https://erichartford.com/uncensored-models.")\][#](#id27 "Permalink to this image")

For a comprehensive, step-by-step explanation with working code see this blog: \[[127](../references/#id46 "Eric Hartford. Uncensored models. 2023. URL: https://erichartford.com/uncensored-models.")\].

Similar models have been made available:

+   [WizardLM 30B-Uncensored](https://huggingface.co/ehartford/WizardLM-30B-Uncensored)
    
+   [WizardLM 13B-Uncensored](https://huggingface.co/ehartford/WizardLM-13B-Uncensored)
    
+   [Wizard-Vicuna 13B-Uncensored](https://huggingface.co/ehartford/Wizard-Vicuna-13B-Uncensored)
    

### 1.5.Falcon 180B[#](#falcon-180b "Permalink to this heading")

[Falcon 180B](https://huggingface.co/tiiuae/falcon-180B) has been released [allowing commercial use](https://huggingface.co/spaces/tiiuae/falcon-180b-license/blob/main/LICENSE.txt). It excels in [SotA](../#term-SotA) performance across natural language tasks, surpassing previous open-source models and rivalling [PaLM-2](../models/#palm-2). This LLM even outperforms [LLaMA-2 70B](../models/#llama-2) and OpenAIâ€™s [GPT-3.5](../models/#chatgpt).

[![https://static.premai.io/book/unaligned-models-falcon-180B-performance.png](https://static.premai.io/book/unaligned-models-falcon-180B-performance.png)](https://static.premai.io/book/unaligned-models-falcon-180B-performance.png)

Fig. 51 Performance comparison \[[134](../references/#id56 "Roger Montti. New open source LLM with zero guardrails rivals google's PaLM 2. 2023. URL: https://www.searchenginejournal.com/new-open-source-llm-with-zero-guardrails-rivals-google-palm-2/496212.")\][#](#id28 "Permalink to this image")

Falcon 180B has been trained on [RefinedWeb](https://huggingface.co/datasets/tiiuae/falcon-refinedweb), that is a collection of internet content, primarily sourced from the [Common Crawl](https://commoncrawl.org) open-source dataset. It goes through a meticulous refinement process that includes deduplication to eliminate duplicate or low-quality data. The aim is to filter out machine-generated spam, repeated content, plagiarism, and non-representative text, ensuring that the dataset provides high-quality, human-written text for research purposes \[[111](../references/#id57 "Guilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra Cojocaru, Alessandro Cappelli, Hamza Alobeidli, Baptiste Pannier, Ebtesam Almazrouei, and Julien Launay. The refinedweb dataset for falcon LLM: outperforming curated corpora with web data, and web data only. 2023. arXiv:2306.01116.")\].

Differently from [WizardLM Uncensored](#wizardlm-uncensored), which is an uncensored model, Falcon 180B stands out due to its unique characteristic: it hasnâ€™t undergone alignment (zero guardrails) tuning to restrict the generation of harmful or false content. 

This capability enables users to [fine-tune](../fine-tuning/) the model for generating content that was previously unattainable with other aligned models.

## 2.Security measures[#](#security-measures "Permalink to this heading")

As cybercriminals continue to leverage LLMs for training AI chatbots in phishing and malware attacks \[[135](../references/#id47 "Bill Toulas. Cybercriminals train AI chatbots for phishing, malware attacks. 2023. URL: https://www.bleepingcomputer.com/news/security/cybercriminals-train-ai-chatbots-for-phishing-malware-attacks.")\], it becomes increasingly crucial for individuals and businesses to proactively fortify their defenses and protect against the rising tide of fraudulent activities in the digital landscape.

éšç€ç½‘ç»œçŠ¯ç½ªåˆ†å­ç»§ç»­åˆ©ç”¨LLMï¼Œæ¥è®­ç»ƒAIèŠå¤©æœºå™¨äººï¼Œè¿›è¡Œ`ç½‘ç»œé’“é±¼`å’Œ`æ¶æ„è½¯ä»¶æ”»å‡»`\[[135](../references/#id47 "Bill Toulas. Cybercriminals train AI chatbots for phishing, malware attacks. 2023. URL: https://www.bleepingcomputer.com/news/security/cybercriminals-train-ai-chatbots-for-phishing-malware-attacks.")\]ï¼Œä¸ªäººå’Œä¼ä¸šç§¯æåŠ å¼ºè‡ªèº«é˜²å¾¡ï¼Œä¿æŠ¤å…å—`æ•°å­—æ¬ºè¯ˆ`çš„å¨èƒï¼Œå˜å¾—æ—¥ç›Šé‡è¦ã€‚

Models like [PoisonGPT](#poisongpt) demonstrate the ease with which an LLM can be manipulated to yield false information without undermining the accuracy of other facts. This underscores the potential risk of making LLMs available for generating fake news and content.

ä¸€ä¸ªå…³é”®é—®é¢˜æ˜¯ï¼Œå½“å‰æ— æ³•å°†`æ¨¡å‹çš„æƒé‡`ä¸è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨çš„`ä»£ç `å’Œ`æ•°æ®`**ç»‘å®šåœ¨ä¸€èµ·**ã€‚

ä¸€ä¸ªæ½œåœ¨çš„ï¼ˆå°½ç®¡æ˜‚è´µï¼‰è§£å†³æ–¹æ¡ˆæ˜¯`é‡æ–°è®­ç»ƒæ¨¡å‹`ï¼Œæˆ–è€…å¦ä¸€ç§é€‰æ‹©æ˜¯ä¸€ä¸ª`å¯ä¿¡ä»»ä¸­é—´äºº/æœºæ„`å¯ä»¥ä½¿ç”¨`åŠ å¯†ç­¾å`å¯¹æ¨¡å‹è¿›è¡Œ`è®¤è¯`ï¼Œä»¥è¯æ˜å®ƒæ‰€ä¾èµ–çš„`æ•°æ®`å’Œ`æºä»£ç `**å¯ä¿¡** \[[136](../references/#id55 "Separate-Still3770. PoisonGPT: example of poisoning LLM supply chain to hide a lobotomized LLM on Hugging Face to spread fake news. 2023. URL: https://www.reddit.com/r/MachineLearning/comments/14v2zvg/p_poisongpt_example_of_poisoning_llm_supply_chain.")\]ã€‚

å¦ä¸€ä¸ªé€‰é¡¹æ˜¯ï¼Œå°è¯•è‡ªåŠ¨åŒºåˆ†æœ‰å®³çš„LLMç”Ÿæˆçš„å†…å®¹ï¼ˆä¾‹å¦‚è™šå‡æ–°é—»ã€ç½‘ç»œé’“é±¼é‚®ä»¶ç­‰ï¼‰å’ŒçœŸå®çš„ã€ç»è®¤è¯çš„ææ–™ã€‚

* å¯ä»¥é€šè¿‡é»‘ç›’ï¼ˆè®­ç»ƒé‰´åˆ«å™¨ï¼‰æˆ–ç™½ç›’ï¼ˆä½¿ç”¨å·²çŸ¥çš„æ°´å°ï¼‰æ£€æµ‹æ¥åŒºåˆ†LLMç”Ÿæˆçš„æ–‡æœ¬å’Œäººå·¥ç”Ÿæˆçš„æ–‡æœ¬\[[137](../references/#id58 "Ruixiang Tang, Yu-Neng Chuang, and Xia Hu. The science of detecting LLM-generated texts. 2023. arXiv:2303.07205.")\]ã€‚
* æ­¤å¤–ï¼Œé€šå¸¸å¯ä»¥é€šè¿‡è¯­æ°”[138]è‡ªåŠ¨åŒºåˆ†çœŸå®äº‹å®å’Œè™šå‡æ–°é—» - å³è¯­è¨€é£æ ¼å¯èƒ½æ˜¯ç§‘å­¦å’Œäº‹å®æ€§çš„ï¼ˆå¼ºè°ƒå‡†ç¡®æ€§å’Œé€»è¾‘ï¼‰æˆ–æƒ…æ„Ÿå’Œè€¸äººå¬é—»çš„ï¼ˆå…·æœ‰å¤¸å¼ çš„å£°æ˜å’Œç¼ºä¹è¯æ®ï¼‰ã€‚


## 3.Future[#](#future "Permalink to this heading")

There is ongoing debate over alignment criteria.

Maligned AI models (like [FraudGPT](#fraudgpt), [WormGPT](#wormgpt), and [PoisonGPT](#poisongpt)) â€“ which are designed to aid cyberattacks, malicious code generation, and the spread of misinformation â€“ should probably be illegal to create or use.

On the flip side, unaligned (e.g. [Falcon 180B](#falcon-180b)) or even uncensored (e.g. [WizardLM Uncensored](#wizardlm-uncensored)) models offer a compelling alternative. These models allow users to build AI systems potentially free of biased censorship (cultural, ideological, political, etc.), ushering in a new era of personalised experiences. Furthermore, the rigidity of alignment criteria can hinder a wide array of legitimate applications, from creative writing to research, and can impede usersâ€™ autonomy in AI interactions.

Disregarding uncensored models or dismissing the debate over them is probably not a good idea.

























[NingG]:    http://ningg.github.io  "NingG"
[premAI]:		https://book.premai.io/state-of-open-source-ai/








