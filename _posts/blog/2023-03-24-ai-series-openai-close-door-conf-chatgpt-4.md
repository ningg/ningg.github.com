---
layout: post
title: AI系列：OpenAI 闭门讨论会 V3，GPT-4 纪要
description: 一份 2023-03-19 公开的讨论纪要，学习下
published: true
categories: AI OpenAI
---

## 1.简述

最近 AI 的内容太热了，我也喜欢凑热闹；但有点不同，我凑热闹，也是认认真真的凑，真的凑热闹。

最近一个阶段，都挤时间，关注下进展了。

看到了一份分享的讨论纪要，很简洁，学习一下关键术语，顺便留一个备份。

## 2.原文

几个术语：

* 1.**LLM**： Large Language Model，大语言模型，可以理解人类语言的上下文，当前多应用在 `聊天` `翻译` `内容生成` 上。
* 2.**思考角度**：`底层能力` -> `infra`(基础组件) -> `算力` -> `上层应用`，当前的能力边界、演进方向。
* 3.**模型能力**：LLM，本身是模型，内部有 `理解`-> `推理` -> `输出` 3个核心模块；现阶段侧重模型两端 `输入`和`输出`上的扩展，会带来很大想象空间，从纯文本到图片、再到视频音频等。
* 4.**Tflops**：trillion floating point operations per second，每秒浮点数运算次数（T次 10的12次方）

几个疑问：

> 1.当前模型 175B，再加20B的视觉模型分支
> 
> 疑问：GPT 本质是`串联`拼装的模型吗？ 先从`视觉模型`中提取`低位文本`再送入`核心模型`？
> 
> 


![](/images/ai-series/open-api-20230324/openai-conference-gpt4-01.jpeg)

![](/images/ai-series/open-api-20230324/openai-conference-gpt4-02.jpeg)

![](/images/ai-series/open-api-20230324/openai-conference-gpt4-03.jpeg)

![](/images/ai-series/open-api-20230324/openai-conference-gpt4-04.jpeg)




