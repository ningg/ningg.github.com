---
layout: post
title: AI视野：苦涩的教训，通用的原理
description: 人工智能近几十年的发展，每一次的突破，反思之前的做法，都能得到近似的结论：通用计算，人力的知识并不一定是唯一的
published: true
categories: 科技历史 AI视野
---

> 识别一切优秀的事情、学习。
> 
> 原文地址：[The Bitter Lesson - 2019](http://www.incompleteideas.net/IncIdeas/BitterLesson.html)
> 
> 译文地址：[苦涩的教训](https://baoyu.io/translations/ai/bitter-lesson)


## 1.通用方法，最优

70 年人工智能研究给我们的最大启示是：依赖**计算能力**的`通用方法`最终表现最佳，而且优势明显。

这背后的主要原因是`摩尔定律`，也就是计算成本持续以指数级下降。

* 大部分 AI 研究都是在假设计算资源固定的情况下进行的（在这种情况下，利用人类知识几乎是提升性能的唯一途径），
* 但实际上，在稍长于一般研究项目的时间里，可用的计算资源会大幅增加。
* 研究者为了在`短期`内取得突破，尝试利用自己对特定领域的`人类知识`，但从长远看，关键在于`计算能力`的利用。
* 这两者原本不必相互冲突，但在实践中却常常如此。

投入其中一个领域的时间，就意味着在另一个上的缺失。

* 此外，人们在一种方法上的投资也会形成心理承诺。
* 而基于`人类知识`的方法往往会使系统变得`复杂`，`不利`于利用计算能力的`通用方法`。

有很多例子显示 AI 研究者是如何迟迟才领悟到这个苦涩的教训，回顾这些案例非常有启发性。

## 2.典型示例

以**计算机国际象棋**为例，1997 年击败世界冠军卡斯帕罗夫的方法主要是`深度搜索`。当时，大多数计算机国际象棋研究者对此表示失望，因为他们更倾向于利用对棋局特殊结构的人类理解。然而，当一个简单但基于搜索的方法，结合特殊的硬件和软件展现出巨大效能时，这些基于人类知识的研究者并不愿意接受失败。他们认为，尽管这次“蛮力”搜索获胜，但它并非一种通用策略，也不是人类下棋的方式。这些研究者本希望基于人类理解的方法能够取胜，对实际结果感到失望。

在**计算机围棋**的发展中，也出现了类似的模式，只是晚了 20 年。最初的努力都在于避免搜索，尽可能利用对游戏的人类理解和特殊特征，但一旦有效地应用了大规模搜索，这些努力都显得微不足道，甚至有害。在这个过程中，通过自我对弈学习价值函数（在很多其他游戏中也是这样，甚至包括国际象棋，尽管在 1997 年首次击败世界冠军的程序中学习的作用并不大）也非常关键。自我对弈学习和一般学习，就像搜索一样，能够充分利用大量计算资源。在计算机围棋和国际象棋中，研究者最初都是试图利用人类的理解来减少搜索的需要，但最终通过接受`搜索`和`学习`才取得了巨大的成功。

在**语音识别**领域，1970 年代由 DARPA 赞助的一场早期比赛就是一个例子。参赛者包括使用了大量人类知识（如对单词、音素、人类声道的理解）的特殊方法，而另一边则是更依赖统计和大量计算的新方法，基于隐马尔可夫模型（HMMs）。最终，`基于统计的方法`战胜了基于`人类知识`的方法。这导致了自然语言处理领域的一次重大转变，随着时间的推移，统计和计算开始成为该领域的主导。深度学习在语音识别中的兴起是这一趋势的最新体现。深度学习方法更少依赖人类知识，使用更多的计算资源，并通过在大型训练集上的学习，极大地提升了语音识别系统的性能。与游戏领域相似，研究人员总是试图创建一个按照他们自己的思维方式工作的系统，但这种尝试最终证明是逆向而行，不仅浪费了大量的研究时间，而且在`大量计算资源`可用并找到`有效利用方法`的情况下，这种尝试显得更是多余。


**计算机视觉**领域也经历了相似的发展模式。早期的方法试图通过搜索边缘、广义圆柱体或 SIFT 特征来处理视觉问题。但在今天，这些方法都被淘汰了。现代的深度学习神经网络仅使用卷积和某些类型的不变性概念，取得了更好的表现。

这是一个重要的教训。作为一个领域，我们还没有完全吸取这一教训，仍在重蹈覆辙。为了识别并避免这种错误，我们必须理解其吸引力所在。

我们必须领悟到，试图构建一个**基于我们认为自己思考方式的系统**是`行不通`的。苦涩的教训源于这样的历史观察：

* 1) 人工智能研究者经常试图将`知识`融入他们的`代理`中；
* 2) 这在`短期内`总是有益的，也让研究者感到`满足`；但 
* 3) 从长远来看，这种做法会导致进步停滞，甚至`阻碍`进一步的`发展`；
* 4) 真正的突破性进展，最终是通过一个相反的方法实现的，这个方法基于通过`搜索`和`学习`来扩大计算的规模。

这种成功带有苦涩，往往消化不良，因为它是在人类中心化方法之上取得的。

从这个苦涩的教训中，我们应该明白`通用方法`的**巨大力量**，即那些随着计算能力的增长而持续扩展的方法。在这方面，似乎可以无限扩展的两种方法是**搜索**和**学习**。

苦涩教训中的另一个关键点是，

* 人类心灵的实质内容极其复杂，不可能简化；
* 我们应该放弃试图简单化地理解心灵内容，如空间、物体、多重代理或对称性等概念。
* 这些都是外部世界中任意而复杂的部分，不应该成为我们构建的核心；
* 相反，我们应该构建的是那些，能够发现并捕捉这种任意复杂性的元方法。
* 这些方法的核心在于，它们能够找到良好的近似，但寻找这些近似的过程应该由我们的方法来完成，而不是我们亲自动手。
* 我们希望 AI 代理能像我们一样具有发现能力，而不是仅仅包含我们已有的发现。
* 将我们的发现直接构建进去，只会使我们更难看清如何实现发现的过程。

下面的内容，值得思考：

> 另一些尝试的结果，可能提供了完全不同的思路，并暗示了一种完全不同的路线。那就是，智能并非只有人的（或类人的）一种模式。
> 
> （足够）强大的计算能力，和（足够）海量的数据，就有可能产生一定程度的智能。这既否定了人脑的神圣性，也否定了人类知识的神圣性。
> 
> 否定人的特殊性，结论就是人只不过是算力大于其他生物的超级计算机而已。但是，人有意识/情绪/情感。
























[NingG]:    http://ningg.github.com  "NingG"

